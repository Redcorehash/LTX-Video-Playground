# Lightricks/LTX-Video-Playground

[![–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç](https://img.shields.io/badge/–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π_—Å–∞–π—Ç-Lightricks-blue?style=flat-square&logo=lightricks&logoColor=white)](https://www.lightricks.com)
[![GitHub –ü—Ä–æ–µ–∫—Ç](https://img.shields.io/badge/GitHub-LTX_Video-black?style=flat-square&logo=github)](https://github.com/Lightricks/LTX-Video)
[![ComfyUI](https://img.shields.io/badge/ComfyUI-LTX_Video-green?style=flat-square&logo=github)](https://github.com/Lightricks/ComfyUI-LTXVideo)
[![–î–µ–º–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ](https://img.shields.io/badge/–î–µ–º–æ_–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ-Hugging_Face-yellow?style=flat-square&logo=huggingface)](https://huggingface.co/spaces/Lightricks/LTX-Video-Playground)
[![–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è](https://img.shields.io/badge/–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è-Lightricks-orange?style=flat-square&logo=huggingface)](https://huggingface.co/Lightricks)
[![–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∏–¥–µ–æ](https://img.shields.io/badge/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã_–≤–∏–¥–µ–æ-–°–∫–∞—á–∞—Ç—å-blue?style=flat-square)](https://download.ru/folders/xpmp2Pcq)
[![–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π](https://img.shields.io/badge/–†–µ–∑—É–ª—å—Ç–∞—Ç—ã_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π-–°–∫–∞—á–∞—Ç—å-purple?style=flat-square)](https://download.ru/folders/uKzUOQsT)
[![Twitter](https://img.shields.io/badge/–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è-Twitter-1DA1F2?style=flat-square&logo=twitter)](https://twitter.com/Lightricks)
[![GitHub](https://img.shields.io/badge/–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è-GitHub-black?style=flat-square&logo=github)](https://github.com/lightricks)

–ú–æ–¥–µ–ª—å **LTX-Video-Playground** –æ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ **Lightricks** –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ. –≠—Ç–∞ –º–æ–¥–µ–ª—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è, —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ–∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–µ—Ä–µ–¥–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.

## –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ**: –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ–∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
- **–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ**: –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ, –≤–∫–ª—é—á–∞—è –æ–±—Ä–µ–∑–∫—É, –Ω–∞–ª–æ–∂–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞.
- **–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞, —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –∏ –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á.
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏**: –õ–µ–≥–∫–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ–¥–∏–∞.

## –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

–ö–æ–¥ –±—ã–ª –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω —Å Python 3.10.5, CUDA –≤–µ—Ä—Å–∏–∏ 12.2 –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç PyTorch >= 2.1.2.

```bash
git clone https://github.com/Lightricks/LTX-Video.git
cd LTX-Video

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv env
source env/bin/activate
python -m pip install -e .\[inference-script\]
Then, download the model from [Hugging Face](https://huggingface.co/Lightricks/LTX-Video) 

```python
from huggingface_hub import snapshot_download

model_path = 'PATH'   # The local directory to save downloaded checkpoint
snapshot_download("Lightricks/LTX-Video", local_dir=model_path, local_dir_use_symlinks=False, repo_type='model')
```

#### Inference

To use our model, please follow the inference code in [inference.py](https://github.com/Lightricks/LTX-Video/blob/main/inference.py):

##### For text-to-video generation:

```bash
python inference.py --ckpt_dir 'PATH' --prompt "PROMPT" --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED
```

##### For image-to-video generation:

```bash
python inference.py --ckpt_dir 'PATH' --prompt "PROMPT" --input_image_path IMAGE_PATH --height HEIGHT --width WIDTH --num_frames NUM_FRAMES --seed SEED
```

### Diffusers üß®

LTX Video is compatible with the [Diffusers Python library](https://huggingface.co/docs/diffusers/main/en/index). It supports both text-to-video and image-to-video generation.

Make sure you install `diffusers` before trying out the examples below.

```bash
pip install -U git+https://github.com/huggingface/diffusers
```

Now, you can run the examples below:

```py
import torch
from diffusers import LTXPipeline
from diffusers.utils import export_to_video

pipe = LTXPipeline.from_pretrained("Lightricks/LTX-Video", torch_dtype=torch.bfloat16)
pipe.to("cuda")

prompt = "A woman with long brown hair and light skin smiles at another woman with long blonde hair. The woman with brown hair wears a black jacket and has a small, barely noticeable mole on her right cheek. The camera angle is a close-up, focused on the woman with brown hair's face. The lighting is warm and natural, likely from the setting sun, casting a soft glow on the scene. The scene appears to be real-life footage"
negative_prompt = "worst quality, inconsistent motion, blurry, jittery, distorted"

video = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    width=704,
    height=480,
    num_frames=161,
    num_inference_steps=50,
).frames[0]
export_to_video(video, "output.mp4", fps=24)
```

For image-to-video:

```py
import torch
from diffusers import LTXImageToVideoPipeline
from diffusers.utils import export_to_video, load_image

pipe = LTXImageToVideoPipeline.from_pretrained("Lightricks/LTX-Video", torch_dtype=torch.bfloat16)
pipe.to("cuda")

image = load_image(
    "https://huggingface.co/datasets/a-r-r-o-w/tiny-meme-dataset-captioned/resolve/main/images/8.png"
)
prompt = "A young girl stands calmly in the foreground, looking directly at the camera, as a house fire rages in the background. Flames engulf the structure, with smoke billowing into the air. Firefighters in protective gear rush to the scene, a fire truck labeled '38' visible behind them. The girl's neutral expression contrasts sharply with the chaos of the fire, creating a poignant and emotionally charged scene."
negative_prompt = "worst quality, inconsistent motion, blurry, jittery, distorted"

video = pipe(
    image=image,
    prompt=prompt,
    negative_prompt=negative_prompt,
    width=704,
    height=480,
    num_frames=161,
    num_inference_steps=50,
).frames[0]
export_to_video(video, "output.mp4", fps=24)
```


